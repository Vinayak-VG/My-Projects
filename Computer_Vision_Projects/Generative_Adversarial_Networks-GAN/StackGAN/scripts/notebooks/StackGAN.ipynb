{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StackGAN",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aseJKbjHqljJ"
      },
      "source": [
        "#**StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks**\n",
        "\n",
        "In this project, I have implemented the StackGAN Model\n",
        "\n",
        "**StackGAN Paper** : [StackGAN](https://arxiv.org/pdf/1612.03242v2.pdf)\n",
        "\n",
        "**Dataset Download** - [CUB-Dataset Images](http://www.vision.caltech.edu/visipedia/CUB-200-2011.html)\n",
        ", [CUB-Dataset Text Description](https://drive.google.com/file/d/0B3y_msrWZaXLT1BZdVdycDY5TEE/view?resourcekey=0-sZrhftoEfdvHq6MweAeCjA)\n",
        "\n",
        "**Special Note**\n",
        "\n",
        "All file paths used below as specific to my system. Please change them accordingly if you are using the code as it is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uKmxnEcEJHC"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentence-transformers\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "from torchvision.utils import save_image\n",
        "from PIL import Image\n",
        "import PIL\n",
        "import pickle\n",
        "from torch.utils.data import Dataset\n",
        "from glob import glob\n",
        "import time\n",
        "import gc\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sentence_transformers import SentenceTransformer, util"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9muyVzOdTm-K",
        "outputId": "cb26e8c8-c09e-4461-8a64-373b61d592db"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDDe25p1W4bd"
      },
      "source": [
        "## **Downloading the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBbX6QT_W9j3"
      },
      "source": [
        "%cd /content\n",
        "# !gdown --id 1hbzc_P1FuxMkcabkgn9ZKinBwW683j45      # Uncomment this if you are downloading the dataset for the first time\n",
        "!tar -xzvf /content/drive/MyDrive/CUB_200_2011.tgz\n",
        "\n",
        "!gdown --id 0B3y_msrWZaXLT1BZdVdycDY5TEE\n",
        "!unzip /content/birds.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuTQTGvlHHSH"
      },
      "source": [
        "## **Loading the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naTFbqWW4A8Y"
      },
      "source": [
        "PATH = '/content/drive/MyDrive/CUB_Dataset'\n",
        "batch_size = 64\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aYUybsS5MQq"
      },
      "source": [
        "''' Dataloader for StageI Training'''\n",
        "\n",
        "class CUB_Dataset(Dataset):\n",
        "    def __init__(self, root_dir, mode = 'train', transform = True):\n",
        "        self.data_dir = root_dir\n",
        "        self.mode = mode\n",
        "        self.transforms = transform\n",
        "        self.bbox = self.load_bbox()     \n",
        "        self._init_dataset()\n",
        "        self.filenames = self.load_filenames()\n",
        "        if transform:\n",
        "            self._init_transform()\n",
        "\n",
        "    def _init_dataset(self):\n",
        "        self.files = []\n",
        "        self.text_files = []\n",
        "        dirs = sorted(os.listdir(os.path.join(\"/content/CUB_200_2011/images\")))\n",
        "        if self.mode == 'train': \n",
        "            for dir in range(len(dirs)):\n",
        "                files = sorted(glob(os.path.join(\"/content/CUB_200_2011/images\", dirs[dir], '*.jpg')))         \n",
        "                self.files += files\n",
        "                text_file = sorted(glob(os.path.join(\"/content/birds/text_c10\", dirs[dir], '*.txt')))\n",
        "                self.text_files += text_file\n",
        "\n",
        "        else:\n",
        "            print(\"No Such Dataset Mode\")\n",
        "            return None\n",
        "\n",
        "    def load_bbox(self):\n",
        "        bbox_path = os.path.join('/content/CUB_200_2011/bounding_boxes.txt')\n",
        "        df_bounding_boxes = pd.read_csv(bbox_path,\n",
        "                                        delim_whitespace=True,\n",
        "                                        header=None).astype(int)\n",
        "        filepath = os.path.join('/content/CUB_200_2011/images.txt')\n",
        "        df_filenames = pd.read_csv(filepath, delim_whitespace=True, header=None)\n",
        "        filenames = df_filenames[1].tolist()\n",
        "        filename_bbox = {img_file[:-4]: [] for img_file in filenames}\n",
        "        numImgs = len(filenames)\n",
        "        for i in range(0, numImgs):\n",
        "            # bbox = [x-left, y-top, width, height]\n",
        "            bbox = df_bounding_boxes.iloc[i][1:].tolist()\n",
        "\n",
        "            key = filenames[i][:-4]\n",
        "            filename_bbox[key] = bbox\n",
        "        return filename_bbox\n",
        "\n",
        "    def get_img(self, img_path, bbox):\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        width, height = img.size\n",
        "        if bbox is not None:\n",
        "            R = int(np.maximum(bbox[2], bbox[3]) * 0.75)\n",
        "            center_x = int((2 * bbox[0] + bbox[2]) / 2)\n",
        "            center_y = int((2 * bbox[1] + bbox[3]) / 2)\n",
        "            y1 = np.maximum(0, center_y - R)\n",
        "            y2 = np.minimum(height, center_y + R)\n",
        "            x1 = np.maximum(0, center_x - R)\n",
        "            x2 = np.minimum(width, center_x + R)\n",
        "            img = img.crop([x1, y1, x2, y2])\n",
        "        load_size = int(64 * 76 / 64)\n",
        "        img = img.resize((load_size, load_size), PIL.Image.BILINEAR)\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img\n",
        "\n",
        "    def load_filenames(self):\n",
        "        filepath = os.path.join('/content/birds/train/filenames.pickle')\n",
        "        with open(filepath, 'rb') as f:\n",
        "            filenames1 = pickle.load(f)\n",
        "        filepath = os.path.join('/content/birds/test/filenames.pickle')\n",
        "        with open(filepath, 'rb') as f:\n",
        "            filenames2 = pickle.load(f)\n",
        "        filenames = filenames1 + filenames2\n",
        "        return filenames\n",
        "\n",
        "    def _init_transform(self):\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.RandomCrop((64, 64)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        key = self.filenames[index]\n",
        "        bbox = self.bbox[key]\n",
        "        img = self.get_img(self.files[index], bbox)\n",
        "        text = self.text_files[index]\n",
        "        return img, text\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "trainset = CUB_Dataset(root_dir='/content/CUB_200_2011/images')\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDPEh7w-2CT7"
      },
      "source": [
        "'''Dataloader for StageII Training'''\n",
        "\n",
        "class CUB_Dataset_2(Dataset):\n",
        "    def __init__(self, root_dir, mode = 'train', transform = True):\n",
        "        self.data_dir = root_dir\n",
        "        self.mode = mode\n",
        "        self.transforms = transform\n",
        "        self.bbox = self.load_bbox()     \n",
        "        self._init_dataset()\n",
        "        self.filenames = self.load_filenames()\n",
        "        if transform:\n",
        "            self._init_transform()\n",
        "\n",
        "    def _init_dataset(self):\n",
        "        self.files = []\n",
        "        self.text_files = []\n",
        "        self.stage1_img_files = []\n",
        "        dirs = sorted(os.listdir(os.path.join(\"/content/CUB_200_2011/images\")))\n",
        "        if self.mode == 'train': \n",
        "            for dir in range(len(dirs)):\n",
        "                files = sorted(glob(os.path.join(\"/content/CUB_200_2011/images\", dirs[dir], '*.jpg')))         \n",
        "                self.files += files\n",
        "                text_file = sorted(glob(os.path.join(\"/content/birds/text_c10\", dirs[dir], '*.txt')))\n",
        "                self.text_files += text_file\n",
        "                stage_1_files = sorted(glob(os.path.join(\"/content/drive/MyDrive/StackGAN/StackGAN-1_Images\", dirs[dir], '*.png')))\n",
        "                self.stage1_img_files += stage_1_files\n",
        "\n",
        "        else:\n",
        "            print(\"No Such Dataset Mode\")\n",
        "            return None\n",
        "\n",
        "    def load_bbox(self):\n",
        "        bbox_path = os.path.join('/content/CUB_200_2011/bounding_boxes.txt')\n",
        "        df_bounding_boxes = pd.read_csv(bbox_path,\n",
        "                                        delim_whitespace=True,\n",
        "                                        header=None).astype(int)\n",
        "        filepath = os.path.join('/content/CUB_200_2011/images.txt')\n",
        "        df_filenames = pd.read_csv(filepath, delim_whitespace=True, header=None)\n",
        "        filenames = df_filenames[1].tolist()\n",
        "        filename_bbox = {img_file[:-4]: [] for img_file in filenames}\n",
        "        numImgs = len(filenames)\n",
        "        for i in range(0, numImgs):\n",
        "            # bbox = [x-left, y-top, width, height]\n",
        "            bbox = df_bounding_boxes.iloc[i][1:].tolist()\n",
        "\n",
        "            key = filenames[i][:-4]\n",
        "            filename_bbox[key] = bbox\n",
        "        return filename_bbox\n",
        "\n",
        "    def get_img(self, img_path, bbox):\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        width, height = img.size\n",
        "        if bbox is not None:\n",
        "            R = int(np.maximum(bbox[2], bbox[3]) * 0.75)\n",
        "            center_x = int((2 * bbox[0] + bbox[2]) / 2)\n",
        "            center_y = int((2 * bbox[1] + bbox[3]) / 2)\n",
        "            y1 = np.maximum(0, center_y - R)\n",
        "            y2 = np.minimum(height, center_y + R)\n",
        "            x1 = np.maximum(0, center_x - R)\n",
        "            x2 = np.minimum(width, center_x + R)\n",
        "            img = img.crop([x1, y1, x2, y2])\n",
        "        load_size = int(256 * 76 / 64)\n",
        "        img = img.resize((load_size, load_size), PIL.Image.BILINEAR)\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img\n",
        "\n",
        "    def load_filenames(self):\n",
        "        filepath = os.path.join('/content/birds/train/filenames.pickle')\n",
        "        with open(filepath, 'rb') as f:\n",
        "            filenames1 = pickle.load(f)\n",
        "        filepath = os.path.join('/content/birds/test/filenames.pickle')\n",
        "        with open(filepath, 'rb') as f:\n",
        "            filenames2 = pickle.load(f)\n",
        "        filenames = filenames1 + filenames2\n",
        "        return filenames\n",
        "\n",
        "    def _init_transform(self):\n",
        "        self.transform1 = transforms.Compose([\n",
        "            #transforms.RandomCrop((64, 64)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.RandomCrop((256, 256)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        key = self.filenames[index]\n",
        "        bbox = self.bbox[key]\n",
        "        img = self.get_img(self.files[index], bbox)\n",
        "        text = self.text_files[index]\n",
        "        stageI_img = Image.open(self.stage1_img_files[index]).convert('RGB')\n",
        "        stageI_img = self.transform1(stageI_img)\n",
        "        return stageI_img, img, text\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.stage1_img_files)\n",
        "\n",
        "trainset2 = CUB_Dataset_2(root_dir='/content/CUB_200_2011/images')\n",
        "trainloader2 = DataLoader(trainset2, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True, pin_memory = True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgzskbbQHNZ8"
      },
      "source": [
        "## **StackGAN Model**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbeVpGvpWlne"
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv2d') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "    elif classname.find('Linear') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.fill_(0.0)\n",
        "\n",
        "class Conditioning_Augmentation_StageI(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Conditioning_Augmentation_StageI, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(768, 256)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = x.to(device)\n",
        "        y = self.relu(self.fc1(x))\n",
        "        u0 = y[:, :128]\n",
        "        logvar = y[:, 128:]\n",
        "        sigma0 = torch.exp(logvar/2)\n",
        "        epsilon = torch.randn((x.shape[0], 128)).to(device)\n",
        "        out = u0 + sigma0*epsilon\n",
        "        return out, u0, logvar\n",
        "\n",
        "class StageI_GAN_Gen(nn.Module):\n",
        "    def __init__(self, condaug1):\n",
        "        super(StageI_GAN_Gen, self).__init__()\n",
        "\n",
        "        # In: [batch_size, 128]\n",
        "        self.CA1 = condaug1()\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(228, 4*4*128*8),\n",
        "            nn.BatchNorm1d(4*4*128*8),\n",
        "            nn.ReLU(True))\n",
        "        \n",
        "        self.upsample1 = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv1 = nn.Conv2d(128*8, 64*8, kernel_size=3, stride=1, padding=1, bias = False)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(64*8)\n",
        "\n",
        "        self.upsample2 = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv2 = nn.Conv2d(64*8, 32*8, kernel_size=3, stride=1, padding=1, bias = False)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(32*8)\n",
        "\n",
        "        self.upsample3 = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv3 = nn.Conv2d(32*8, 16*8, kernel_size=3, stride=1, padding=1, bias = False)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(16*8)\n",
        "\n",
        "        self.upsample4 = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv4 = nn.Conv2d(16*8, 8*8, kernel_size=3, stride=1, padding=1, bias = False)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(8*8)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(8*8, 3, kernel_size=3, stride=1, padding=1, bias = False)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x.to(device)\n",
        "        x, u0, logvar = self.CA1(x)\n",
        "        z = torch.randn((x.shape[0], 100)).to(device)\n",
        "        x = torch.cat((x, z), 1)\n",
        "        x = self.fc(x)\n",
        "        x = torch.reshape(x, (-1, 128*8, 4, 4))\n",
        "        x = self.relu(self.batchnorm1(self.conv1(self.upsample1(x))))\n",
        "        x = self.relu(self.batchnorm2(self.conv2(self.upsample2(x))))\n",
        "        x = self.relu(self.batchnorm3(self.conv3(self.upsample3(x))))\n",
        "        x = self.relu(self.batchnorm4(self.conv4(self.upsample4(x))))\n",
        "        x = self.tanh(self.conv5(x))\n",
        "\n",
        "        return x, u0, logvar\n",
        "\n",
        "class DownSample1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DownSample1, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias = False)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias = False)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias = False)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias = False)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(512)\n",
        "\n",
        "        self.leakyrelu = nn.LeakyReLU(0.2, inplace = True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = x.to(device)\n",
        "        x = self.leakyrelu(self.conv1(x))\n",
        "        x = self.leakyrelu(self.batchnorm2(self.conv2(x)))\n",
        "        x = self.leakyrelu(self.batchnorm3(self.conv3(x)))\n",
        "        x = self.leakyrelu(self.batchnorm4(self.conv4(x)))\n",
        "\n",
        "        return x\n",
        "\n",
        "class StageI_GAN_Dis(nn.Module):\n",
        "    def __init__(self, downsample):\n",
        "        super(StageI_GAN_Dis, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(768, 128)\n",
        "        self.downsample = downsample()\n",
        "        self.conv1 = nn.Conv2d(640, 512, kernel_size=1, stride=1, bias = False)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(512)\n",
        "        self.leakyrelu = nn.LeakyReLU(0.2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(512, 1, kernel_size = 4, stride = 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, text):\n",
        "        \n",
        "        x = x.to(device)\n",
        "        text = text.to(device)\n",
        "        x = self.downsample(x)   \n",
        "        text = self.fc1(text)\n",
        "        text = text.unsqueeze(2)\n",
        "        text = text.unsqueeze(3)\n",
        "        text1 = torch.cat((text, text, text, text), 2)\n",
        "        text = torch.cat((text1, text1, text1, text1), 3)\n",
        "        x = torch.cat((x, text), 1)\n",
        "        x = self.leakyrelu(self.batchnorm1(self.conv1(x))) \n",
        "        x = self.conv2(x)\n",
        "        x = torch.squeeze(x, 3)\n",
        "        x = torch.squeeze(x, 2)\n",
        "        x = self.sigmoid(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Conditioning_Augmentation_StageII(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Conditioning_Augmentation_StageII, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(768, 256)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = x.to(device)\n",
        "        #print(x.shape)\n",
        "        y = self.relu(self.fc1(x))\n",
        "        u0 = y[:, :128]\n",
        "        logvar = y[:, 128:]\n",
        "        sigma0 = torch.exp(logvar/2)\n",
        "        epsilon = torch.randn((x.shape[0], 128)).to(device)\n",
        "        out = u0 + sigma0*epsilon\n",
        "        return out, u0, logvar\n",
        "\n",
        "\n",
        "class DownSample2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DownSample2, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 128, kernel_size=3, stride=1, padding=1, bias = False)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias = False)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias = False)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(512)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x.to(device)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.batchnorm2(self.conv2(x)))\n",
        "        x = self.relu(self.batchnorm3(self.conv3(x)))\n",
        "\n",
        "        return x\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias = False)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(512)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias = False)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(512)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x.to(device)\n",
        "        identity = x\n",
        "        x = self.relu(self.batchnorm1(self.conv1(x)))\n",
        "        x = self.batchnorm2(self.conv2(x))\n",
        "        x = x + identity\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class UpSampling2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UpSampling2, self).__init__()\n",
        "\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.conv1 = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1, bias = False)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1, bias = False)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1, bias = False)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1, bias = False)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(32, 3, kernel_size=3, stride=1, padding=1, bias = False)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x.to(device)\n",
        "        x = self.relu(self.batchnorm1(self.conv1(self.upsample(x))))\n",
        "        x = self.relu(self.batchnorm2(self.conv2(self.upsample(x))))\n",
        "        x = self.relu(self.batchnorm3(self.conv3(self.upsample(x))))\n",
        "        x = self.relu(self.batchnorm4(self.conv4(self.upsample(x))))\n",
        "        x = self.conv5(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class StageII_GAN_Gen(nn.Module):\n",
        "    def __init__(self, downsample, resblock, upsample, condaug2):\n",
        "        super(StageII_GAN_Gen, self).__init__()\n",
        "\n",
        "        self.downsample = downsample()\n",
        "        self.resblock = resblock()\n",
        "        self.upsample = upsample()\n",
        "        self.CA2 = condaug2()\n",
        "        self.conv = nn.Conv2d(640, 512, kernel_size=3, stride=1, padding=1, bias = False)\n",
        "        self.batchnorm = nn.BatchNorm2d(512)\n",
        "        self.relu = nn.ReLU(True)\n",
        "        self.tanh = nn.Tanh()\n",
        "    def forward(self, x, text):\n",
        "\n",
        "        x = x.to(device)\n",
        "        text = text.to(device)\n",
        "        text, u0, logvar = self.CA2(text)\n",
        "        text = text.unsqueeze(2)\n",
        "        text = text.unsqueeze(3)\n",
        "        text = text.repeat(1, 1, 16, 16)\n",
        "        x = self.downsample(x)\n",
        "        x = torch.cat((x, text), 1)\n",
        "        x = self.relu(self.batchnorm(self.conv(x)))\n",
        "        x = self.resblock(self.resblock(self.resblock(self.resblock(x))))\n",
        "        x = self.upsample(x)\n",
        "        x = self.tanh(x)\n",
        "\n",
        "        return x, u0, logvar\n",
        "\n",
        "class DownSample3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DownSample3, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size = 4, stride = 2, padding = 1, bias = False)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size = 4, stride = 2, padding = 1, bias = False)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size = 4, stride = 2, padding = 1, bias = False)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(256, 512, kernel_size = 4, stride = 2, padding = 1, bias = False)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(512)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(512, 1024, kernel_size = 4, stride = 2, padding = 1, bias = False)\n",
        "        self.batchnorm5 = nn.BatchNorm2d(1024)\n",
        "\n",
        "        self.conv6 = nn.Conv2d(1024, 2048, kernel_size = 4, stride = 2, padding = 1, bias = False)\n",
        "        self.batchnorm6 = nn.BatchNorm2d(2048)\n",
        "\n",
        "        self.conv7 = nn.Conv2d(2048, 1024, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.batchnorm7 = nn.BatchNorm2d(1024)\n",
        "\n",
        "        self.conv8 = nn.Conv2d(1024, 512, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.batchnorm8 = nn.BatchNorm2d(512)\n",
        "        self.leakyrelu = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x.to(device)\n",
        "        x = self.leakyrelu(self.conv1(x))\n",
        "        x = self.leakyrelu(self.batchnorm2(self.conv2(x)))\n",
        "        x = self.leakyrelu(self.batchnorm3(self.conv3(x)))\n",
        "        x = self.leakyrelu(self.batchnorm4(self.conv4(x)))\n",
        "        x = self.leakyrelu(self.batchnorm5(self.conv5(x)))\n",
        "        x = self.leakyrelu(self.batchnorm6(self.conv6(x)))\n",
        "        x = self.leakyrelu(self.batchnorm7(self.conv7(x)))\n",
        "        x = self.leakyrelu(self.batchnorm8(self.conv8(x)))\n",
        "\n",
        "        return x\n",
        "\n",
        "class StageII_GAN_Dis(nn.Module):\n",
        "    def __init__(self, downsample):\n",
        "        super(StageII_GAN_Dis, self).__init__()\n",
        "        \n",
        "        self.fc0 = nn.Linear(768, 128)\n",
        "        self.downsample = downsample()\n",
        "        self.conv1 = nn.Conv2d(640, 512, kernel_size=3, stride=1, padding = 1, bias = False)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(512)\n",
        "        self.leakyrelu = nn.LeakyReLU(0.2)\n",
        "        self.conv2 = nn.Conv2d(512, 1, kernel_size = 4, stride = 4)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, text):\n",
        "        \n",
        "        x = x.to(device)\n",
        "        text = text.to(device)\n",
        "        x = self.downsample(x)  \n",
        "        text = self.fc0(text)\n",
        "        text = text.unsqueeze(2)\n",
        "        text = text.unsqueeze(3)\n",
        "        text = text.repeat(1, 1, 4, 4)\n",
        "        x = torch.cat((x, text), 1)\n",
        "        x = self.leakyrelu(self.batchnorm1(self.conv1(x))) \n",
        "        x = self.sigmoid(self.conv2(x))  \n",
        "        x = x.squeeze(3)\n",
        "        x = x.squeeze(2)\n",
        "\n",
        "        return x\n",
        "\n",
        "StageI_Gen = StageI_GAN_Gen(Conditioning_Augmentation_StageI).to(device)\n",
        "StageI_Gen = StageI_Gen.apply(weights_init)\n",
        "StageI_Dis = StageI_GAN_Dis(DownSample1).to(device)\n",
        "StageI_Dis = StageI_Dis.apply(weights_init)\n",
        "StageII_Gen = StageII_GAN_Gen(DownSample2, ResidualBlock, UpSampling2, Conditioning_Augmentation_StageII).to(device)\n",
        "StageII_Gen = StageII_Gen.apply(weights_init)\n",
        "StageII_Dis = StageII_GAN_Dis(DownSample3).to(device)\n",
        "StageII_Dis = StageII_Dis.apply(weights_init)\n",
        "sbert_model = SentenceTransformer('paraphrase-mpnet-base-v2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znCyaf4lHWKl"
      },
      "source": [
        "## **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdQNkrUaai1K"
      },
      "source": [
        "epoch_D1losses = []             \n",
        "epoch_G1losses = []\n",
        "epoch_D2losses = []             \n",
        "epoch_G2losses = []\n",
        "epoch_Real_Score = []\n",
        "epoch_Fake_Score = []\n",
        "epoch_Generator_Score = []"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fng55psn7JfS"
      },
      "source": [
        "epochs = 600\n",
        "lrG = 0.0002\n",
        "lrD = 0.0002\n",
        "\n",
        "optimizerD1 = torch.optim.Adam(StageI_Dis.parameters(), lr=lrD, betas=(0.5,0.999))\n",
        "optimizerG1 = torch.optim.Adam(StageI_Gen.parameters(), lr=lrG, betas=(0.5,0.999))\n",
        "\n",
        "BCEloss = nn.BCELoss()\n",
        "\n",
        "def KL_loss(mu, logvar):\n",
        "    # -0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
        "    KLD = torch.mean(KLD_element).mul_(-0.5)\n",
        "    return KLD\n",
        "\n",
        "def train_StageI_Dis(real_images, wrong_images, text, optimizer):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    real_images = real_images.to(device)\n",
        "    text = text.to(device)\n",
        "    real_pred = StageI_Dis(real_images, text)\n",
        "    real_targets = torch.ones(real_images.size(0),1)\n",
        "    real_pred = real_pred.to(device)\n",
        "    real_targets = real_targets.to(device)\n",
        "    real_loss = BCEloss(real_pred, real_targets)\n",
        "    real_score = torch.mean(real_pred).item()\n",
        "\n",
        "    fake_images, mu, logvar = StageI_Gen(text)\n",
        "    fake_pred1 = StageI_Dis(fake_images, text)\n",
        "    fake_targets1 = torch.zeros(fake_images.size(0),1)\n",
        "    fake_pred1 = fake_pred1.to(device)\n",
        "    fake_targets1 = fake_targets1.to(device)\n",
        "    fake_loss1 = BCEloss(fake_pred1, fake_targets1)\n",
        "    fake_score1 = torch.mean(fake_pred1).item()\n",
        "\n",
        "    wrong_images = wrong_images.to(device)\n",
        "    fake_pred2 = StageI_Dis(wrong_images, text)\n",
        "    fake_targets2 = torch.zeros(wrong_images.size(0),1)\n",
        "    fake_pred2 = fake_pred2.to(device)\n",
        "    fake_targets2 = fake_targets2.to(device)\n",
        "    fake_loss2 = BCEloss(fake_pred2, fake_targets2)\n",
        "    fake_score2 = torch.mean(fake_pred2).item()\n",
        "\n",
        "    discriminator_loss = real_loss + (fake_loss1 + fake_loss2)/2\n",
        "    discriminator_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return discriminator_loss.item(), real_score, (fake_score1+fake_score2)/2\n",
        "\n",
        "\n",
        "def train_StageI_Gen(text, optimizer):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    text = text.to(device)\n",
        "    generator_images, mu, logvar = StageI_Gen(text)\n",
        "    generator_pred = StageI_Dis(generator_images, text)\n",
        "    generator_targets = torch.ones(batch_size, 1)\n",
        "    generator_pred = generator_pred.to(device)\n",
        "    generator_targets = generator_targets.to(device)\n",
        "    gen_bin_loss = BCEloss(generator_pred, generator_targets)\n",
        "    generator_score = torch.mean(generator_pred).item()\n",
        "    kl_loss = KL_loss(mu, logvar)\n",
        "\n",
        "    generator_loss = gen_bin_loss + 2*kl_loss\n",
        "    generator_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return generator_loss.item(), gen_bin_loss, kl_loss, generator_score\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "'''Load the weights if you have trained already'''\n",
        "\n",
        "# if os.path.isfile(\"/content/drive/MyDrive/StackGAN/checkpoints/StageI_Dis_GAN.pt\"):\n",
        "#     checkpointD1 = torch.load('/content/drive/MyDrive/StackGAN/checkpoints/StageI_Dis_GAN.pt')\n",
        "#     StageI_Dis.load_state_dict(checkpointD1['model_state_dict'])\n",
        "#     StageI_Dis.to(device)\n",
        "#     optimizerD1.load_state_dict(checkpointD1['optimizer_state_dict'])\n",
        "#     epoch = checkpointD1['epoch']\n",
        "#     best_D1loss = checkpointD1['loss']\n",
        "\n",
        "# if os.path.isfile(\"/content/drive/MyDrive/StackGAN/checkpoints/StageI_Gen_GAN.pt\"):\n",
        "#     checkpointG1 = torch.load('/content/drive/MyDrive/StackGAN/checkpoints/StageI_Gen_GAN.pt')\n",
        "#     StageI_Gen.load_state_dict(checkpointG1['model_state_dict'])\n",
        "#     StageI_Gen.to(device)\n",
        "#     optimizerG1.load_state_dict(checkpointG1['optimizer_state_dict'])\n",
        "#     epoch = checkpointG1['epoch']\n",
        "#     best_G1loss = checkpointG1['loss']\n",
        "\n",
        "def save_samples(index1, text, show=True):\n",
        "    fake_images, a, b = StageI_Gen(text)\n",
        "    fake_images = fake_images[0:16,:,:,:]\n",
        "    fake_fname = 'generated-images-{}.png'.format(index1)\n",
        "    save_image((fake_images), os.path.join(\"/content/drive/MyDrive/GAN Images/Birds/birds-5\", fake_fname), nrow=4)\n",
        "    if show:\n",
        "        fig, ax = plt.subplots(figsize=(8, 8))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(fake_images.cpu().detach(), nrow=8).permute(1, 2, 0))\n",
        "\n",
        "''' Stage1 Training'''\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    start_time = time.monotonic()\n",
        "    \n",
        "    print(f\"Epoch: {epoch + 1}\")\n",
        "    train_D1Loss_batch = []\n",
        "    train_G1Loss_batch = []\n",
        "    train_real_score = []\n",
        "    train_fake_score = []\n",
        "    train_generator_score = []\n",
        "\n",
        "    # model.eval()\n",
        "    for idx,(real_images, text) in enumerate(trainloader):\n",
        "\n",
        "        '''If you want to use HuggingFace Sentence Transformer'''\n",
        "        text = list(text)\n",
        "        embedding = []\n",
        "        for i in range(len(text)):\n",
        "            my_file = open(text[i], \"r\")\n",
        "            content = my_file.read()\n",
        "            embedding.append(content)\n",
        "        emb = sbert_model.encode(embedding)\n",
        "        emb = torch.from_numpy(emb)\n",
        "\n",
        "        wrong_images = torch.flip(real_images, [0])\n",
        "        discriminator_loss, real_score, fake_score = train_StageI_Dis(real_images, wrong_images, emb, optimizerD1)\n",
        "        generator_loss, a, b, generator_score = train_StageI_Gen(emb, optimizerG1)\n",
        "        train_D1Loss_batch.append(discriminator_loss)\n",
        "        train_G1Loss_batch.append(generator_loss)\n",
        "        train_real_score.append(real_score)\n",
        "        train_fake_score.append(fake_score)\n",
        "        train_generator_score.append(generator_score)\n",
        "\n",
        "        if (idx+1)%180 == 0:\n",
        "            emb_save = emb[0:16, :]\n",
        "            save_samples(epoch+1, emb_save, show=False)\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    if (epoch+1)%50 == 0:\n",
        "        lrG = lrG/2\n",
        "        lrD = lrD/2\n",
        "        print(f\"Learning Rate Halved: {lrG} {lrD}\")\n",
        "\n",
        "    epoch_D1losses.append(sum(train_D1Loss_batch)/len(trainloader))\n",
        "    epoch_G1losses.append(sum(train_G1Loss_batch)/len(trainloader))\n",
        "    epoch_Real_Score.append(sum(train_real_score)/len(trainloader))\n",
        "    epoch_Fake_Score.append(sum(train_fake_score)/len(trainloader))\n",
        "    epoch_Generator_Score.append(sum(train_generator_score)/len(trainloader))\n",
        "\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': StageI_Dis.state_dict(),\n",
        "        'optimizer_state_dict': optimizerD1.state_dict(),\n",
        "        'loss': epoch_D1losses[-1],\n",
        "        }, '/content/drive/MyDrive/StackGAN/checkpoints/StageI_Dis_GAN.pt')\n",
        "\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': StageI_Gen.state_dict(),\n",
        "        'optimizer_state_dict': optimizerG1.state_dict(),\n",
        "        'loss': epoch_G1losses[-1],\n",
        "        }, '/content/drive/MyDrive/StackGAN/checkpoints/StageI_Gen_GAN.pt')\n",
        "\n",
        "    print(f\"Discriminator Epoch Loss: {epoch_D1losses[-1]:.5f}   Generator Epoch Loss: {epoch_G1losses[-1]:.5f}   Real Score: {epoch_Real_Score[-1]:.5f}   Fake Score: {epoch_Fake_Score[-1]:.5f}   Generator Score: {epoch_Generator_Score[-1]:.5f}\")\n",
        "\n",
        "    end_time = time.monotonic()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    print(\"\\n\\n\\n TIME TAKEN FOR THE EPOCH: {} mins and {} seconds\".format(epoch_mins, epoch_secs))\n",
        "    \n",
        "\n",
        "print(\"OVERALL TRAINING COMPLETE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P2gufw9hGes"
      },
      "source": [
        "epochs = 600\n",
        "lrG = 0.0002\n",
        "lrD = 0.0002\n",
        "\n",
        "optimizerD2 = torch.optim.Adam(StageII_Dis.parameters(), lr=lrD, betas=(0.5,0.999))\n",
        "optimizerG2 = torch.optim.Adam(StageII_Gen.parameters(), lr=lrG, betas=(0.5,0.999))\n",
        "\n",
        "BCEloss = nn.BCELoss()\n",
        "\n",
        "def KL_loss(mu, logvar):\n",
        "    # -0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
        "    KLD = torch.mean(KLD_element).mul_(-0.5)\n",
        "    return KLD\n",
        "\n",
        "def train_StageII_Dis(real_images, wrong_images, stageI_img, text, optimizer):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    real_images = real_images.to(device)\n",
        "    text = text.to(device)\n",
        "    real_pred = StageII_Dis(real_images, text)\n",
        "    real_targets = torch.ones(real_images.size(0),1)\n",
        "    real_pred = real_pred.to(device)\n",
        "    real_targets = real_targets.to(device)\n",
        "    real_loss = BCEloss(real_pred, real_targets)\n",
        "    real_score = torch.mean(real_pred).item()\n",
        "\n",
        "    fake_images, mu, logvar = StageII_Gen(stageI_img, text)\n",
        "\n",
        "    fake_pred1 = StageII_Dis(fake_images, text)\n",
        "    fake_targets1 = torch.zeros(fake_images.size(0),1)\n",
        "    fake_pred1 = fake_pred1.to(device)\n",
        "    fake_targets1 = fake_targets1.to(device)\n",
        "    fake_loss1 = BCEloss(fake_pred1, fake_targets1)\n",
        "    fake_score1 = torch.mean(fake_pred1).item()\n",
        "\n",
        "    wrong_images = wrong_images.to(device)\n",
        "    fake_pred2 = StageII_Dis(wrong_images, text)\n",
        "    fake_targets2 = torch.zeros(wrong_images.size(0),1)\n",
        "    fake_pred2 = fake_pred2.to(device)\n",
        "    fake_targets2 = fake_targets2.to(device)\n",
        "    fake_loss2 = BCEloss(fake_pred2, fake_targets2)\n",
        "    fake_score2 = torch.mean(fake_pred2).item()\n",
        "\n",
        "    discriminator_loss = (fake_loss1 + fake_loss2)/2 + real_loss\n",
        "    discriminator_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return discriminator_loss.item(), real_score, (fake_score1 + fake_score2)/2\n",
        "\n",
        "\n",
        "def train_StageII_Gen(gen1_image, text, optimizer):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    gen1_image = gen1_image.to(device)\n",
        "    text = text.to(device)\n",
        "    generator_images, mu, logvar = StageII_Gen(gen1_image, text)\n",
        "    generator_pred = StageII_Dis(generator_images, text)\n",
        "    generator_targets = torch.ones(batch_size, 1)\n",
        "    generator_pred = generator_pred.to(device)\n",
        "    generator_targets = generator_targets.to(device)\n",
        "    gen_bin_loss = BCEloss(generator_pred, generator_targets)\n",
        "    generator_score = torch.mean(generator_pred).item()\n",
        "    kl_loss = KL_loss(mu, logvar)\n",
        "\n",
        "    generator_loss = gen_bin_loss + 2*kl_loss\n",
        "    generator_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return generator_loss.item(), generator_score\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "# if os.path.isfile(\"/content/drive/MyDrive/StackGAN/checkpoints/StageII_Dis_GAN.pt\"):\n",
        "#     checkpointD2 = torch.load('/content/drive/MyDrive/StackGAN/checkpoints/StageII_Dis_GAN.pt')\n",
        "#     StageII_Dis.load_state_dict(checkpointD2['model_state_dict'])\n",
        "#     StageII_Dis.to(device)\n",
        "#     optimizerD2.load_state_dict(checkpointD2['optimizer_state_dict'])\n",
        "#     epoch = checkpointD2['epoch']\n",
        "#     best_D2loss = checkpointD2['loss']\n",
        "\n",
        "# if os.path.isfile(\"/content/drive/MyDrive/StackGAN/checkpoints/StageII_Gen_GAN.pt\"):\n",
        "#     checkpointG2 = torch.load('/content/drive/MyDrive/StackGAN/checkpoints/StageII_Gen_GAN.pt')\n",
        "#     StageII_Gen.load_state_dict(checkpointG2['model_state_dict'])\n",
        "#     StageII_Gen.to(device)\n",
        "#     optimizerG2.load_state_dict(checkpointG2['optimizer_state_dict'])\n",
        "#     epoch = checkpointG2['epoch']\n",
        "#     best_G2loss = checkpointG2['loss']\n",
        "\n",
        "def save_samples(index1, stageI_img, text, show=True):\n",
        "    fake_images, a, b = StageII_Gen(stageI_img, text)\n",
        "    fake_images = fake_images[0:4,:,:,:]\n",
        "    fake_fname = 'generated-images-{}.png'.format(index1)\n",
        "    save_image((fake_images), os.path.join(\"/content/drive/MyDrive/GAN Images/Birds/birds-6\", fake_fname), nrow=2)\n",
        "    if show:\n",
        "        fig, ax = plt.subplots(figsize=(8, 8))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(fake_images.cpu().detach(), nrow=8).permute(1, 2, 0))\n",
        "\n",
        "''' Stage2 Training'''\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    start_time = time.monotonic()\n",
        "    \n",
        "    print(f\"Epoch: {epoch + 1}\")\n",
        "    train_D2Loss_batch = []\n",
        "    train_G2Loss_batch = []\n",
        "    train_real_score = []\n",
        "    train_fake_score = []\n",
        "    train_generator_score = []\n",
        "\n",
        "    for idx,(stageI_img, real_images, text) in enumerate(trainloader2):\n",
        "        '''If you want to use HuggingFace Sentence Transformer'''\n",
        "        text = list(text)\n",
        "        embedding = []\n",
        "        for i in range(len(text)):\n",
        "            my_file = open(text[i], \"r\")\n",
        "            content = my_file.read()\n",
        "            embedding.append(content)\n",
        "        emb = sbert_model.encode(embedding)\n",
        "        emb = torch.from_numpy(emb)\n",
        "\n",
        "        wrong_images = torch.flip(real_images, [0])\n",
        "        discriminator_loss, real_score, fake_score = train_StageII_Dis(real_images, wrong_images, stageI_img, emb, optimizerD2)\n",
        "        generator_loss, generator_score = train_StageII_Gen(stageI_img, emb, optimizerG2)\n",
        "        train_D2Loss_batch.append(discriminator_loss)\n",
        "        train_G2Loss_batch.append(generator_loss)\n",
        "        train_real_score.append(real_score)\n",
        "        train_fake_score.append(fake_score)\n",
        "        train_generator_score.append(generator_score)\n",
        "\n",
        "        if (idx+1)%180 == 0:\n",
        "            emb_save = emb[0:4, :]\n",
        "            stageI_img_save = stageI_img[0:4, :, :, :]\n",
        "            save_samples(epoch+1+372, stageI_img_save, emb_save, show=False)\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    if (epoch+1)%50 == 0:\n",
        "        lrG = lrG/2\n",
        "        lrD = lrD/2\n",
        "        print(f\"Learning Rate Halved: {lrG} {lrD}\")\n",
        "\n",
        "    epoch_D2losses.append(sum(train_D2Loss_batch)/len(trainloader2))\n",
        "    epoch_G2losses.append(sum(train_G2Loss_batch)/len(trainloader2))\n",
        "    epoch_Real_Score.append(sum(train_real_score)/len(trainloader2))\n",
        "    epoch_Fake_Score.append(sum(train_fake_score)/len(trainloader2))\n",
        "    epoch_Generator_Score.append(sum(train_generator_score)/len(trainloader2))\n",
        "\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': StageII_Dis.state_dict(),\n",
        "        'optimizer_state_dict': optimizerD2.state_dict(),\n",
        "        'loss': epoch_D2losses[-1],\n",
        "        }, '/content/drive/MyDrive/StackGAN/checkpoints/StageII_Dis_GAN.pt')\n",
        "\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': StageII_Gen.state_dict(),\n",
        "        'optimizer_state_dict': optimizerG2.state_dict(),\n",
        "        'loss': epoch_G2losses[-1],\n",
        "        }, '/content/drive/MyDrive/StackGAN/checkpoints/StageII_Gen_GAN.pt')\n",
        "\n",
        "    print(f\"Discriminator Epoch Loss: {epoch_D2losses[-1]:.5f}   Generator Epoch Loss: {epoch_G2losses[-1]:.5f}   Real Score: {epoch_Real_Score[-1]:.5f}   Fake Score: {epoch_Fake_Score[-1]:.5f}   Generator Score: {epoch_Generator_Score[-1]:.5f}\")\n",
        "\n",
        "    end_time = time.monotonic()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    print(\"\\n\\n\\n TIME TAKEN FOR THE EPOCH: {} mins and {} seconds\".format(epoch_mins, epoch_secs))\n",
        "    \n",
        "\n",
        "print(\"OVERALL TRAINING COMPLETE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFbAwohlWR0k"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEWczH-lwYJP"
      },
      "source": [
        "lrD = 0.0002\n",
        "lrG = 0.0002\n",
        "optimizerD1 = torch.optim.Adam(StageI_Dis.parameters(), lr=lrD, betas=(0.5,0.999))\n",
        "optimizerG1 = torch.optim.Adam(StageI_Gen.parameters(), lr=lrG, betas=(0.5,0.999))\n",
        "optimizerD2 = torch.optim.Adam(StageII_Dis.parameters(), lr=lrD, betas=(0.5,0.999))\n",
        "optimizerG2 = torch.optim.Adam(StageII_Gen.parameters(), lr=lrG, betas=(0.5,0.999))\n",
        "\n",
        "checkpointG1 = torch.load('/content/drive/MyDrive/StackGAN/checkpoints/StageI_Gen_GAN.pt')\n",
        "StageI_Gen.load_state_dict(checkpointG1['model_state_dict'])\n",
        "StageI_Gen.to(device)\n",
        "optimizerG1.load_state_dict(checkpointG1['optimizer_state_dict'])\n",
        "epoch = checkpointG1['epoch']\n",
        "best_G1loss = checkpointG1['loss']\n",
        "print(best_G1loss)\n",
        "\n",
        "checkpointG2 = torch.load('/content/drive/MyDrive/StackGAN/checkpoints/StageII_Gen_GAN.pt')\n",
        "StageII_Gen.load_state_dict(checkpointG2['model_state_dict'])\n",
        "StageII_Gen.to(device)\n",
        "optimizerG2.load_state_dict(checkpointG2['optimizer_state_dict'])\n",
        "epoch = checkpointG2['epoch']\n",
        "best_G2loss = checkpointG2['loss']\n",
        "print(best_G2loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9v8yOIzwH2S"
      },
      "source": [
        "StageI_Gen.eval()\n",
        "StageII_Gen.eval()\n",
        "emb = sbert_model.encode('''The bird is black in colour with white belly''')\n",
        "emb = torch.from_numpy(emb)\n",
        "emb = emb.unsqueeze(0)\n",
        "generator_images, mu, logvar = StageI_Gen(emb)\n",
        "generator_images2, mu, logvar = StageII_Gen(generator_images, emb)\n",
        "generator_images2 = generator_images2.squeeze(0)\n",
        "fake_fname = '0.png'\n",
        "save_image((generator_images2), os.path.join(\"/content\", fake_fname), nrow=1)"
      ],
      "execution_count": 123,
      "outputs": []
    }
  ]
}